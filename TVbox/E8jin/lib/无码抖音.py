#!/data/data/com.termux/files/usr/bin/python3
# -*- coding: utf-8 -*-
import aiohttp
import asyncio
import re
import time
import os
import json
import threading
from collections import defaultdict
from urllib.parse import urljoin, quote
import concurrent.futures

# ç¦ç”¨SSLè­¦å‘Š
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

MOBILE_UA = "Mozilla/5.0 (Linux; Android 13; SM-S901U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Mobile Safari/537.36"

class DouyinSpider:
    def __init__(self):
        self.base_url = 'https://douyin.wmdy7.top/douyin/'
        self.session = None
        self.connector = None
        
        self.categories = {}
        category_str = "å›½äº§ç²¾å“$13#ç½‘æ›åƒç“œ$6#è‡ªæ‹å·æ‹$7#ä¼ åª’å‡ºå“$8#ç½‘çº¢ä¸»æ’­$9#å¤§ç¥æ¢èŠ±$10#æŠ–é˜´è§†é¢‘$11#å›½äº§å…¶å®ƒ$12#æ—¥éŸ©ç²¾å“$14#æ—¥éŸ©æ— ç $15#æ—¥éŸ©æœ‰ç $16#ä¸­æ–‡å­—å¹•$20#èè‰å°‘å¥³$21#äººå¦»ç†Ÿå¦‡$22#éŸ©å›½ä¸»æ’­$23#æ—¥éŸ©å…¶å®ƒ$24#æ¬§ç¾ç²¾å“$5#æ¬§ç¾æ— ç $25#æ¬§ç¾å¦ç±»$26#æ¬§ç¾å…¶å®ƒ$27#AIæ¢è„¸$28#AVè§£è¯´$29#ä¸‰çº§ä¼¦ç†$30#æˆäººåŠ¨æ¼«$31#å›½äº§è§†é¢‘$1#æ— ç ä¸­æ–‡$2#3$3#4$4"
        for item in category_str.split('#'):
            if '$' in item:
                name, cid = item.split('$')
                self.categories[cid] = name
        
        self.category_videos = defaultdict(list)
        self.seen_urls = set()
        self.save_path = os.path.expanduser("~/douyin_full_videos.txt")
        self.pause_flag = False
        self.exit_flag = False
        self.lock = threading.Lock()
        self.total_extracted = 0
        self.semaphore = asyncio.Semaphore(50)  # æé«˜å¹¶å‘æ•°é‡

    async def create_session(self):
        """åˆ›å»ºaiohttpä¼šè¯"""
        timeout = aiohttp.ClientTimeout(total=15)
        self.connector = aiohttp.TCPConnector(limit=50, ssl=False)
        self.session = aiohttp.ClientSession(
            connector=self.connector,
            timeout=timeout,
            headers={
                'User-Agent': MOBILE_UA,
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
            }
        )

    async def close_session(self):
        """å…³é—­aiohttpä¼šè¯"""
        if self.session:
            await self.session.close()
        if self.connector:
            await self.connector.close()

    async def get_html(self, url, retry=3):
        """å¼‚æ­¥è·å–é¡µé¢å†…å®¹"""
        if self.exit_flag:
            return None
            
        while self.pause_flag:
            await asyncio.sleep(1)
            if self.exit_flag:
                return None
                
        try:
            if not url.startswith('http'):
                url = urljoin(self.base_url, url)
                
            async with self.semaphore:
                async with self.session.get(url, allow_redirects=True) as response:
                    if response.status == 200:
                        return await response.text(encoding='utf-8')
                    elif response.status == 404:
                        return None
                    elif retry > 0:
                        await asyncio.sleep(1)
                        return await self.get_html(url, retry - 1)
        except aiohttp.ClientError as e:
            if retry > 0:
                await asyncio.sleep(1)
                return await self.get_html(url, retry - 1)
        return None

    def clean_title(self, title):
        """æ¸…ç†æ ‡é¢˜"""
        title = re.sub(r'<[^>]+>', '', title)
        title = re.sub(r'[\[\]ã€ã€‘]', '', title)
        title = re.sub(r'\s+', ' ', title)
        return title.strip()

    def extract_video_list(self, html):
        """ä»åˆ—è¡¨é¡µæå–è§†é¢‘é“¾æ¥å’Œæ ‡é¢˜"""
        videos = []
        if not html:
            return videos
        
        array_pattern = r'lazyload\"(.*?)</a>'
        array_matches = re.findall(array_pattern, html, re.S | re.I)
        
        for array_match in array_matches:
            title_pattern = r'title=\"(.*?)\"'
            title_match = re.search(title_pattern, array_match)
            title = title_match.group(1) if title_match else ""
            
            link_pattern = r'href=\"(.*?)\"'
            link_match = re.search(link_pattern, array_match)
            link = link_match.group(1) if link_match else ""
            
            if title and link:
                title = self.clean_title(title)
                
                if not link.startswith('http'):
                    link = urljoin(self.base_url, link)
                
                with self.lock:
                    if link in self.seen_urls:
                        continue
                    self.seen_urls.add(link)
                
                videos.append({
                    'title': title,
                    'url': link
                })
        
        return videos

    def extract_m3u8_from_detail(self, html):
        """ä»è¯¦æƒ…é¡µæå–m3u8é“¾æ¥"""
        if not html:
            return None
            
        patterns = [
            r'var player_.*?url\":\"(.*?)\"',
            r'url\s*[:=]\s*["\'](https?://[^"\']+?\.m3u8[^"\']*)["\']',
            r'(https?://[^\s"\']+?\.m3u8[^\s"\']*)',
            r'file\s*[:=]\s*["\'](https?://[^"\']+?\.m3u8[^"\']*)["\']',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, html, re.I)
            for match in matches:
                m3u8_url = match.replace('\\/', '/')
                if m3u8_url.startswith('//'):
                    m3u8_url = 'https:' + m3u8_url
                if '.m3u8' in m3u8_url:
                    return m3u8_url
                    
        return None

    async def process_video(self, video, category_name):
        """å¼‚æ­¥å¤„ç†å•ä¸ªè§†é¢‘ï¼Œå¹¶å°†ç»“æœå­˜å…¥å†…å­˜"""
        if self.exit_flag:
            return
            
        try:
            detail_html = await self.get_html(video['url'])
            if not detail_html:
                return
                
            m3u8_url = self.extract_m3u8_from_detail(detail_html)
            if m3u8_url:
                video['playback_url'] = m3u8_url
                with self.lock:
                    self.category_videos[category_name].append(video)
                    self.total_extracted += 1
                    if self.total_extracted % 10 == 0:
                        print(f"  âœ… å·²æå– {self.total_extracted} ä¸ªè§†é¢‘")
                
        except Exception as e:
            pass

    async def crawl_category_page(self, category_id, category_name, page):
        """å¼‚æ­¥çˆ¬å–ç‰¹å®šåˆ†ç±»çš„å•é¡µ"""
        url = f'https://douyin.wmdy34.fun/douyin/vodtype/{category_id}-{page}.html'
        html = await self.get_html(url)
        if not html:
            return None
            
        videos = self.extract_video_list(html)
        if not videos:
            return []
            
        tasks = [self.process_video(video, category_name) for video in videos]
        await asyncio.gather(*tasks)
        
        next_page_pattern = f'vodtype/{category_id}-{page+1}.html'
        if next_page_pattern not in html:
            return []
            
        return videos

    async def crawl_all_category_pages(self, category_id, category_name):
        """å¼‚æ­¥çˆ¬å–ä¸€ä¸ªåˆ†ç±»çš„æ‰€æœ‰é¡µç """
        print(f"ğŸ“ å¼€å§‹çˆ¬å–: {category_name}")
        page = 1
        while not self.exit_flag:
            if self.pause_flag:
                await asyncio.sleep(1)
                continue
                
            videos = await self.crawl_category_page(category_id, category_name, page)
            
            if not videos:
                print(f"  â¹ï¸ {category_name} çˆ¬å–å®Œæˆæˆ–æ‰¾ä¸åˆ°æ›´å¤šå†…å®¹")
                break
            
            page += 1
            await asyncio.sleep(0.5)
            
    def save_results(self):
        """ä¿å­˜ç»“æœ - æŒ‰åˆ†ç±»ç»„ç»‡"""
        if not self.category_videos:
            return
            
        try:
            with open(self.save_path, 'w', encoding='utf-8') as f:
                total_count = 0
                # ä¿®å¤ï¼šéå†æ‰€æœ‰åˆ†ç±»åç§°ï¼Œè€Œä¸æ˜¯åˆ†ç±»ID
                for category_name in self.categories.values():
                    videos = self.category_videos.get(category_name, [])
                    if not videos:
                        continue
                        
                    total_count += len(videos)
                    f.write(f"\n{category_name},#genre#\n")
                    
                    for video in videos:
                        clean_title = video['title'].replace(',', 'ï¼Œ')
                        f.write(f"{clean_title},{video['playback_url']}\n")
            
            print(f"ğŸ’¾ æœ€ç»ˆä¿å­˜: {total_count} ä¸ªè§†é¢‘")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")

    async def listen_commands(self):
        """å¼‚æ­¥ç›‘å¬ç”¨æˆ·å‘½ä»¤"""
        print("\nğŸ“± å‘½ä»¤: p=æš‚åœ/ç»§ç»­, q=é€€å‡º")
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as pool:
            while not self.exit_flag:
                try:
                    cmd = await loop.run_in_executor(pool, input, "> ")
                    cmd = cmd.strip().lower()
                    
                    if cmd == 'p':
                        self.pause_flag = not self.pause_flag
                        status = "æš‚åœ" if self.pause_flag else "ç»§ç»­"
                        print(f"â¸ï¸ {status}")
                        
                    elif cmd == 'q':
                        self.exit_flag = True
                        print("ğŸ›‘ æ­£åœ¨é€€å‡º...")
                        break
                        
                except (KeyboardInterrupt, EOFError):
                    self.exit_flag = True
                    break

    async def run_async(self):
        """å¼‚æ­¥ä¸»å‡½æ•°"""
        print("ğŸš€ æŠ–éŸ³è§†é¢‘å…¨ç«™æå–å·¥å…·å¯åŠ¨ (ä¼˜åŒ–ç‰ˆ)")
        print("ğŸ¯ æŒ‰åˆ†ç±»å®æ—¶å†™å…¥æ–‡ä»¶ï¼Œå¹¶æ”¯æŒå…¨å±€å¹¶å‘")
        
        await self.create_session()
        
        try:
            cmd_task = asyncio.create_task(self.listen_commands())
            
            tasks = []
            for category_id, category_name in self.categories.items():
                if self.exit_flag:
                    break
                tasks.append(self.crawl_all_category_pages(category_id, category_name))
            
            await asyncio.gather(*tasks)
                
            if not cmd_task.done():
                cmd_task.cancel()
                try:
                    await cmd_task
                except asyncio.CancelledError:
                    pass
                    
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            await self.close_session()
            self.save_results()
            print(f"\nğŸ‰ å®Œæˆ! å…±æå– {self.total_extracted} ä¸ªè§†é¢‘")

    def run(self):
        """è¿è¡Œå…¥å£"""
        try:
            asyncio.run(self.run_async())
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(self.run_async())
            finally:
                loop.close()

if __name__ == "__main__":
    spider = DouyinSpider()
    spider.run()